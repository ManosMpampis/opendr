#Config File example
save_dir: ./temp/simple_big_ch_very_small_annots_SGD
check_point_name: simple_big_ch_very_small_annots_SGD
model:
  weight_averager:
    name: ExpMovingAverager
    decay: 0.9998
  arch:
    name: NanoDetPlus
    detach_epoch: 10
    backbone:
      name: SimpleCnn_3
      activation: LeakyReLU
      use_depthwise: False
      quant: False
      pretrain: False
    fpn:
      name: SimpleGPAN_1 #PAN #FPN  #PAN a litle slower than FPN
      in_channels: [ 32, 64 ]
      out_channels: 32
      use_depthwise: True
      kernel_size: 5
      num_blocks: 1
      upsample_cfg:
        scale_factor: 2
        mode: bilinear
      activation: LeakyReLU
      quant: False
    head:
      name: SimplifierNanoDetPlusHead_1 #NanoDetPlusHead #NanoDetPlusHead NanoDetHead
      num_classes: 2
      input_channel: 32
      feat_channels: 32
      stacked_convs: 3
      kernel_size: 3 #Only in NanoDetPlusHead
      strides: [ 8, 16 ]
      use_depthwise: True
      reg_max: 7
      activation: LeakyReLU
      quant: False
      fork: False
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0
    # Auxiliary head, only use in training time.
    aux_head:
      name: SimpleConvHead
      num_classes: 2
      input_channel: 64
      feat_channels: 64
      stacked_convs: 4
      strides: [8, 16]
      activation: LeakyReLU
      reg_max: 7
data:
  train:
    input_size: [320, 320] #[w,h]
    keep_ratio: False
    cache_images: _
    pipeline:
      perspective: 0.0
      scale: [0.9, 1.1]
      stretch: [[0.9, 1.1], [0.9, 1.1]]
      rotation: 0
      shear: 0
      translate: 0.0
      flip: 0.5
      jitter_box: 0.1
      hard_pos: 0.0
      hard_pos_ratio: 0.0
      brightness: 0.2
      contrast: [0.8, 1.2]
      saturation: [0.8, 1.1]
      normalize: [[103.71, 108.77, 105.6], [31.51, 28.67, 27.91]]  # very small annots
#      normalize: [[98.45438741, 104.10689567, 98.17277835], [34.79841708, 31.2228376, 29.66469302]]  # full annots
  val:
    input_size: [320, 320] #[2456, 2054] #[640, 640] #[192, 192] #[96, 96] #[1920, 1088] #[w,h]
    keep_ratio: False
    cache_images: _
    pipeline:
      perspective: 0.0
      normalize: [[103.71, 108.77, 105.6], [31.51, 28.67, 27.91]]  # very small annots
#      normalize: [[98.45438741, 104.10689567, 98.17277835], [34.79841708, 31.2228376, 29.66469302]]  # full annots
  bench_test:
    input_size: [2456, 2054] #[1920, 1088] [2456, 2054]
    keep_ratio: False
    pipeline:
      perspective: 0.0
      normalize: [[103.71, 108.77, 105.6], [31.51, 28.67, 27.91]]  # very small annots
#      normalize: [[98.45438741, 104.10689567, 98.17277835], [34.79841708, 31.2228376, 29.66469302]]  # full annots
device:
  gpu_ids: [0]
  workers_per_gpu: 4
  batchsize_per_gpu: 1
  precision: 32
schedule:
  resume: 0
  optimizer:
    name: SGD
    lr: 0.005
    weight_decay: 0.05
  warmup:
    name: linear
    steps: 500
    ratio: 0.0001
  total_epochs: 300
  lr_schedule:
    name: CosineAnnealingWarmRestarts
    T_0: 10
    T_mult: 2
    eta_min: 0.00005
    last_epoch: -1
#    name: CosineAnnealingLR
#    T_max: 300
#    eta_min: 0.00005
  val_intervals: 1
  effective_batchsize: -1
grad_clip: 35
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP
log:
  interval: 10

class_names: ["poaceae", "brassicaceae"]